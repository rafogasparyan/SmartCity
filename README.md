Sure! Here's a **full detailed README** (without emojis or code snippets) for your **SafeRoute AI** project, structured professionally for GitHub or internal documentation:

---

# SafeRoute AI

**SafeRoute AI** is a real-time smart city simulation platform that enhances driver safety by analyzing driving behavior and environmental context. It delivers actionable alerts using advanced stream processing, machine learning, and large language models. This project integrates simulated data streams, Kafka pipelines, Spark streaming, Redis caching, and an LLM-driven assistant to evaluate and improve driver performance.

---

## Project Overview

Modern urban mobility requires intelligent systems that can react to dynamic traffic conditions and driver behavior in real time. SafeRoute AI addresses this challenge by simulating realistic driving journeys and providing real-time suggestions to improve road safety. It serves as both a research prototype and a proof-of-concept for future AI-assisted driver support systems.

---

## Key Features

* Simulated vehicle journey generation, including GPS, speed, weather, and traffic camera data
* Kafka-based data streaming architecture with multiple topics for different data sources
* Spark Structured Streaming for real-time processing, feature aggregation, and windowing
* Route optimization using Google SnapToRoads API and Redis-based caching
* Driver behavior evaluation and suggestions using LLMs integrated through LangChain
* Redis as a fast-access cache for stateful components and event deduplication
* Kafka-based delivery of safety alerts to driver-facing interfaces

---

## Architecture Overview

The system consists of the following core components:

1. **Data Simulation Service**
   Generates realistic driving data streams for GPS, traffic, vehicle, weather, and emergency events. These are published to corresponding Kafka topics.

2. **Apache Kafka**
   Serves as the backbone for real-time communication between microservices. Each event type has its own topic, and all services are decoupled via Kafka.

3. **Apache Spark**
   Processes real-time streams from Kafka, computes metrics (e.g., speeding, hard braking), applies time-window aggregations, and prepares feature batches for evaluation.

4. **Driver Evaluator Service**
   Gathers aggregated trip data and calls an LLM to assess driver behavior. Based on safety patterns and road conditions, it produces detailed feedback for drivers.

5. **LLM-Based Driver Assistant**
   Builds prompts using environmental and behavioral data and queries a GPT-4 model to generate contextual, human-readable alerts. These alerts are pushed back to Kafka.

6. **Route Optimization Service**
   Receives GPS data, enhances it using Googleâ€™s SnapToRoads API, and publishes optimized paths. Redis caching ensures performance by avoiding repeated API calls.

7. **Redis**
   Acts as a high-speed cache for:

   * Recent GPS-to-road coordinate mapping
   * Trip-specific driver state
   * Deduplicated LLM-generated alerts

8. **Docker Compose**
   All services are containerized and run within a shared Docker network, allowing easy orchestration, scalability, and testing.

9. **Amazon S3**
   Used to store exported trip data and logs. This component helps enable future model retraining and offline analysis.

---

## Technologies Used

* Apache Kafka
* Apache Spark (Structured Streaming)
* Redis
* Python
* Google Maps Roads API
* LangChain with GPT-based LLMs
* Docker and Docker Compose
* Amazon S3 (for future storage integration)

---

## Use Cases

* Real-time safety recommendations based on current location, traffic, and behavior
* Evaluation of driver performance post-trip, using historical behavior and aggregated metrics
* Simulation platform for research and academic purposes
* Foundation for commercial driver-assistance applications

---

## Project Goals

* Create a fully containerized and reproducible simulation environment
* Integrate multiple data streams into a single decision-making assistant
* Minimize LLM usage cost by batching and deduplicating alerts intelligently
* Establish groundwork for future ML training datasets

---


---
## TO RUN THE APP

docker-compose up --build


## Credits

Project created by:

* Rafik Gasparyan
* Vahe Aleksanyan
